{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe3db9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a798c0",
   "metadata": {},
   "source": [
    "## <center> BERT Based - NER </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "771d39f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"Data.txt\", \"r\") as f:\n",
    "    # Read the entire file content and join lines into a single string\n",
    "    cars_data = json.loads(\"\".join(f.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "133fe9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def CreateMetadataandTextfromJSON(json_data):\n",
    "    vehicle_data = {\n",
    "        \"vin\": json_data['vin'],\n",
    "        \"vehicle_info\": {\n",
    "            \"vehicle_serial_number\": json_data['serialNbr'],\n",
    "            \"vehicle_body_style_description\": json_data['bodyStyleDesc'],\n",
    "            \"vehicle_brand\": json_data['brand'],\n",
    "            \"marketing_grade_code\": json_data['marketingGrade']['code'],\n",
    "            \"marketing_grade_title\": json_data['marketingGrade']['title']\n",
    "        },\n",
    "        \"engine_info\": {\n",
    "            \"engine_code\": json_data['engine']['engineCd'],\n",
    "            \"engine_number\": json_data['engine']['engineNbr'],\n",
    "            \"engine_name\": json_data['engine']['name'],\n",
    "            \"engine_fuel_type\": json_data['engine']['fuelType'],\n",
    "            \"engine_cylinders_count\": json_data['engine']['noOfCylinders'],\n",
    "            \"engine_horsepower\": json_data['engine']['horsepower']\n",
    "        },\n",
    "        \"price_info\": {\n",
    "            \"price_optional_total_msrp\": json_data['price']['optTotalMsrp'],\n",
    "            \"price_total_msrp\": json_data['price']['totalMsrp'],\n",
    "            \"price_base_msrp\": json_data['price']['baseMsrp'],\n",
    "            \"price_ppo_holdback\": json_data['price']['ppoHoldback']\n",
    "        },\n",
    "        \"color_info\": {\n",
    "            \"interior_color_code\": json_data['intColor']['colorCd'],\n",
    "            \"interior_color_nvs_name\": json_data['intColor']['nvsName'],\n",
    "            \"exterior_color_code\": json_data['extColor']['colorCd'],\n",
    "            \"exterior_color_nvs_name\": json_data['extColor']['nvsName'],\n",
    "            \"exterior_color_hex_code\": json_data['extColor']['colorHexCd'],\n",
    "            \"exterior_color_common_name_display\": json_data['extColor']['commonName']['display'],\n",
    "            \"exterior_color_common_name_generic\": json_data['extColor']['commonName']['generic'],\n",
    "            \"exterior_color_common_name_specific\": json_data['extColor']['commonName']['specific']\n",
    "        },\n",
    "        \"drivetrain_info\": {\n",
    "            \"drivetrain_code\": json_data['drivetrain']['code'],\n",
    "            \"drivetrain_title\": json_data['drivetrain']['title']\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return vehicle_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47f9388a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CategoryField(data):\n",
    "    res = {}\n",
    "    for key in data.keys():\n",
    "        # Initialize the string to accumulate data\n",
    "        combined_string = ''\n",
    "        \n",
    "        # Check if the field is a dictionary, meaning it contains subfields\n",
    "        if isinstance(data[key], dict):\n",
    "            for sub_key in data[key].keys():\n",
    "                try:\n",
    "                    # Add the subfield value to the combined string\n",
    "                    combined_string += \" \" + str(data[key][sub_key])\n",
    "                except:\n",
    "                    print(f\"Not Data Found for {sub_key}\")\n",
    "        \n",
    "        # If combined_string has content, store it in the result dictionary\n",
    "        if combined_string:\n",
    "            res[key] = combined_string.strip()  # Strip to remove leading/trailing spaces\n",
    "            \n",
    "        # Optionally print the key and combined value for debugging\n",
    "        # print(f\"Key: {key}, Combined String: {combined_string}\")\n",
    "    \n",
    "    return res  # Return the result dictionary after processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63e1ddd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "867234d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb60042b5d048828414069ea512263d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vehicle_info = ''\n",
    "engine_info = ''\n",
    "color_info = ''\n",
    "drivetrain_info = ''\n",
    "\n",
    "\n",
    "for idx in tqdm(range(len(cars_data['items']))):\n",
    "    try:\n",
    "        temp_data = CreateMetadataandTextfromJSON(cars_data['items'][idx])\n",
    "        vehicle_info += ' ' + CategoryField(temp_data)['vehicle_info']\n",
    "        engine_info += ' ' + CategoryField(temp_data)['engine_info']\n",
    "        color_info += ' ' + CategoryField(temp_data)['color_info']\n",
    "        drivetrain_info +=' ' + CategoryField(temp_data)['drivetrain_info']\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "254a1639",
   "metadata": {},
   "outputs": [],
   "source": [
    "un = [set(vehicle_info.split(\" \"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "215a2a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\n",
    "    \"nomic-ai/nomic-embed-text-v1.5\",\n",
    "    trust_remote_code=True,\n",
    "    device=\"cpu\", \n",
    "    config_kwargs={\"use_memory_efficient_attention\": False, \"unpad_inputs\": False, \"cache_folder\":\"./\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6877f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f7605ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "def CleanQuery(text):\n",
    "    # Process the query with spaCy NLP pipeline\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Remove stop words\n",
    "    filtered_tokens = [token.text for token in doc if not token.is_stop]\n",
    "\n",
    "    # Join the filtered tokens into a cleaned query\n",
    "    filtered_query = \" \".join(filtered_tokens)\n",
    "    \n",
    "    return filtered_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0848db20",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_embed = model.encode(vehicle_info).tolist()\n",
    "engine_embed = model.encode(engine_info).tolist()\n",
    "color_embed = model.encode(color_info).tolist()\n",
    "drivetrain_embed = model.encode(drivetrain_info).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "90ef8433",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Show the Camry XSE Engine 2024 FWD in white with price less than 40000 Engine G46 042035YFT4MCE9RP2 and 616073\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "16e496eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Count: 11\n"
     ]
    }
   ],
   "source": [
    "FilteredQuery = set(CleanQuery(query).split(\" \"))\n",
    "print(\"Token Count: {}\".format(len(FilteredQuery)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "93cfc503",
   "metadata": {},
   "outputs": [],
   "source": [
    "QueryTokens = []\n",
    "\n",
    "for token in FilteredQuery:\n",
    "    QueryTokens.append({\n",
    "        \"token\":token,\n",
    "        \"embedding\":model.encode(token).tolist()\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "62df164c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"\n",
    "    Calculates the cosine similarity between two vectors.\n",
    "\n",
    "    Args:\n",
    "        vec1: A NumPy array representing the first vector.\n",
    "        vec2: A NumPy array representing the second vector.\n",
    "\n",
    "    Returns:\n",
    "        The cosine similarity score between the two vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    dot_product = np.dot(vec1, vec2.T)  # Transpose vec2 for valid matrix multiplication\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2, axis=1)  # Calculate norms for each row of vec2\n",
    "    return dot_product / (norm_vec1 * norm_vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c1de3bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "dd104467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 768)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec1 = np.matrix([drivetrain_embed,color_embed, engine_embed, vehicle_embed])\n",
    "vec1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6dd1ced8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b4d8d2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: XSE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 3\n",
    "print(\"Token: {}\".format(QueryTokens[idx]['token']))\n",
    "vec2 = np.matrix(QueryTokens[idx]['embedding'])\n",
    "vec2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f71f50ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.24409141],\n",
       "        [0.13395017],\n",
       "        [0.17470156],\n",
       "        [0.15273087]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(vec1, vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174cf271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3bde1292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, AutoModelForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "aca86e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77add875e57f46feab3d6192b8a2cc7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95436429bb214bcdb50e9c062ca782ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "716291a909634220b0f80fe2be895f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6afaeffda1f140228025a26abcad381a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at BERT/checkpoint-3500/ and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path to your checkpoint folder\n",
    "checkpoint_path = \"BERT/checkpoint-3500/\"  # Adjust this to your folder's location\n",
    "\n",
    "# Replace the tokenizer with a pretrained BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Load your fine-tuned model from the checkpoint\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint_path)\n",
    "\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e6cc27cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\"O\": 0, \"color_info\": 1, \"vehicle_info\": 2, \"engine_info\": 3, \"price_info\": 4, \"drivetrain_info\": 5, \"vin\": 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "63bb0425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits: tensor([[ 0.1715, -0.0677, -0.4886,  0.1582, -0.0631, -0.5511, -0.0083]])\n",
      "Predicted probabilities: tensor([[0.1851, 0.1457, 0.0957, 0.1827, 0.1464, 0.0899, 0.1546]])\n",
      "Predicted label: 0\n"
     ]
    }
   ],
   "source": [
    "# Example text input for prediction\n",
    "input_text = \"Hycross\"\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# The outputs include logits. Apply softmax to get probabilities if needed\n",
    "logits = outputs.logits\n",
    "predictions = torch.softmax(logits, dim=1)\n",
    "\n",
    "# Print the predictions\n",
    "print(\"Logits:\", logits)\n",
    "print(\"Predicted probabilities:\", predictions)\n",
    "\n",
    "# If it's a classification model, get the predicted label\n",
    "predicted_label = torch.argmax(predictions, dim=1).item()\n",
    "print(\"Predicted label:\", predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "dbbcc70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'color_info': 1,\n",
       " 'vehicle_info': 2,\n",
       " 'engine_info': 3,\n",
       " 'price_info': 4,\n",
       " 'drivetrain_info': 5,\n",
       " 'vin': 6}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26dd176",
   "metadata": {},
   "source": [
    "### Key Val Pair RnD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f559cf1",
   "metadata": {},
   "source": [
    "* Handle Fuzzy\n",
    "    - brand - TOYOTA\n",
    "    - grade - xse - > XSE/VS SE\n",
    "    - drivetrain - FWD/Front-Wheel Drive\n",
    "    - marketingTitle - Prius Prime XSE 2.0L 4-Cyl. Plug-in Hybrid Engine Front-Wheel Drive\n",
    "    - text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db890d7a",
   "metadata": {},
   "source": [
    "* Workflow\n",
    "    - Query -> Remove Stop Words -> Search In MasterData for Key Val -> UnMatch Tokens get into -> Fuzzy - Fuzzy Results -> Final Query [Match  Tokens from Master Data + Fuzzy Resulst] -> Regex -> KeyVal Pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbbc414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
