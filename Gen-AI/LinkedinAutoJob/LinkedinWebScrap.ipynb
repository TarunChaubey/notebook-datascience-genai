{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "# from webdriver_manager.chrome import ChromiumService\n",
    "from selenium.webdriver.chrome.service import Service as ChromiumService\n",
    "import time\n",
    "import json\n",
    "from selenium.common.exceptions import (\n",
    "    TimeoutException,\n",
    "    NoSuchElementException,\n",
    "    WebDriverException,\n",
    "    ElementNotInteractableException,\n",
    ")\n",
    "\n",
    "user_data_dir = \"C:/Linkedin\"\n",
    "\n",
    "# Set up Chrome options to use a persistent user profile for cookies and cache\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(f\"--user-data-dir={user_data_dir}\")  # Specify the path to store user data\n",
    "chrome_options.add_argument(\"--profile-directory=Profile 1\")  # Specify the profile, e.g., Profile 1\n",
    "\n",
    "url = \"https://www.linkedin.com/search/results/content/?datePosted=%22past-week%22&keywords=hiring%20data%20scientist&origin=FACETED_SEARCH&searchId=f47da7ed-4acd-4098-841a-090ea2244d63&sid=!_Q\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "JobDetails = 'JobDetails'\n",
    "os.makedirs(JobDetails, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Chrome WebDriver\n",
    "driver = webdriver.Chrome(service=ChromiumService(ChromeDriverManager().install()), options=chrome_options)\n",
    "driver.get(url)\n",
    "\n",
    "# Start the timer (60 minutes = 3600 seconds)\n",
    "start_time = time.time()\n",
    "timeout = 3600  # 60 minutes in seconds\n",
    "\n",
    "# Initialize data storage\n",
    "all_posts = []\n",
    "\n",
    "# Function to scroll the page\n",
    "def scroll_page():\n",
    "    # Scroll down one page at a time\n",
    "    body = driver.find_element(By.TAG_NAME, \"body\")\n",
    "    body.send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(2)\n",
    "\n",
    "# Run the extraction loop for 60 minutes\n",
    "while time.time() - start_time < timeout:\n",
    "    try:\n",
    "        # Wait for post containers to load\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"fie-impression-container\")))\n",
    "        \n",
    "        # Find all posts on the current page\n",
    "        post_containers = driver.find_elements(By.CLASS_NAME, \"fie-impression-container\")\n",
    "        \n",
    "        # Process each post individually to keep metadata, email, URL and text together\n",
    "        for idx, post in enumerate(post_containers):\n",
    "            post_data = {}\n",
    "            \n",
    "            # Extract metadata (person name, time posted)\n",
    "            try:\n",
    "                metadata_element = post.find_element(By.CLASS_NAME, \"update-components-actor__container\")\n",
    "                post_data['metadata'] = metadata_element.text\n",
    "            except:\n",
    "                post_data['metadata'] = \"No metadata found\"\n",
    "            \n",
    "            # Extract post text\n",
    "            try:\n",
    "                text_element = post.find_element(By.CSS_SELECTOR, 'span.break-words')\n",
    "                post_data['text'] = text_element.text\n",
    "            except:\n",
    "                post_data['text'] = \"No text found\"\n",
    "            \n",
    "            # Extract emails from this specific post\n",
    "            try:\n",
    "                email_elements = post.find_elements(By.CSS_SELECTOR, \"a[href^='mailto']\")\n",
    "                post_data['emails'] = [email.get_attribute('href').replace('mailto:', '') for email in email_elements]\n",
    "            except:\n",
    "                post_data['emails'] = []\n",
    "            \n",
    "            # Extract URLs from this specific post\n",
    "            try:\n",
    "                url_elements = post.find_elements(By.CSS_SELECTOR, \"a[href]\")\n",
    "                # Define a list of keywords to filter out URLs\n",
    "                keywords = ['keywords']  # You can add more keywords to this list as needed\n",
    "                # Filter out mailto links, internal page links, and URLs containing any of the keywords\n",
    "                post_data['urls'] = [url.get_attribute('href') for url in url_elements \n",
    "                                    if url.get_attribute('href').startswith('http') \n",
    "                                    and not 'mailto:' in url.get_attribute('href')\n",
    "                                    and not any(keyword in url.get_attribute('href') for keyword in keywords)]\n",
    "            except:\n",
    "                post_data['urls'] = []\n",
    "            \n",
    "            # Check if this post is already in our collection (to avoid duplicates)\n",
    "            if post_data not in all_posts:\n",
    "                all_posts.append(post_data)\n",
    "                \n",
    "            \n",
    "            with open(os.path.join(JobDetails, f\"DS_{idx}.json\"), 'w') as f:\n",
    "                json.dump(post_data, f, indent=4)\n",
    "\n",
    "                # # Print the extracted data for this post\n",
    "                # print(f\"Post #{len(all_posts)}:\")\n",
    "                # print(f\"Metadata: {post_data['metadata']}\")\n",
    "                # print(f\"Text: {post_data['text']}\")\n",
    "                # print(f\"Emails: {post_data['emails']}\")\n",
    "                # print(f\"URLs: {post_data['urls']}\")\n",
    "                # print(\"-\" * 50)\n",
    "        \n",
    "        # Scroll to load more posts\n",
    "        scroll_page()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        # If there's an error, wait a bit and try scrolling again\n",
    "        time.sleep(5)\n",
    "        scroll_page()\n",
    "\n",
    "# Print summary\n",
    "print(f\"Extraction complete. Total posts extracted: {len(all_posts)}\")\n",
    "\n",
    "# Close WebDriver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
